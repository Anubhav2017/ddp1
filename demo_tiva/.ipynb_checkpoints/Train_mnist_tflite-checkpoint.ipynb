{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "35d98fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, ReLU, Softmax \n",
    "from tensorflow.keras.models import Sequential\n",
    "import os\n",
    "MODELS_DIR = 'models/'\n",
    "if not os.path.exists(MODELS_DIR):\n",
    "    os.mkdir(MODELS_DIR)\n",
    "MODEL_TF = MODELS_DIR + 'model'\n",
    "MODEL_NO_QUANT_TFLITE = MODELS_DIR + 'model_no_quant.tflite'\n",
    "MODEL_TFLITE = MODELS_DIR + 'model.tflite'\n",
    "MODEL_TFLITE_MICRO = MODELS_DIR + 'model.cc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1efc78a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "X_train = X_train.reshape(-1,28,28,1)\n",
    "X_test = X_test.reshape(-1,28,28,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a512582d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.7465 - accuracy: 0.8612 - val_loss: 0.2082 - val_accuracy: 0.9379\n",
      "INFO:tensorflow:Assets written to: models/model/assets\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(3, kernel_size=(4,4), input_shape=(28,28,1),activation='relu'))\n",
    "model.add(Conv2D(2, kernel_size=(3,3), activation='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10))\n",
    "\n",
    "model.add(Softmax())\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=1)\n",
    "\n",
    "\n",
    "model.save(MODEL_TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1512885b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0989878e-09, 6.6156886e-11, 5.3568381e-09, ..., 9.9999940e-01,\n",
       "        2.0173047e-08, 7.3853224e-10],\n",
       "       [8.5276268e-05, 1.8751254e-02, 9.7987318e-01, ..., 3.4213288e-10,\n",
       "        3.0210307e-05, 2.4638114e-10],\n",
       "       [3.4739728e-08, 9.9684513e-01, 1.2344425e-04, ..., 1.0129134e-05,\n",
       "        1.3136582e-03, 3.4880537e-05],\n",
       "       ...,\n",
       "       [9.1677728e-11, 1.0228922e-08, 2.2157730e-10, ..., 5.6662509e-05,\n",
       "        1.8644149e-06, 1.9878711e-05],\n",
       "       [2.4719059e-04, 9.8279691e-07, 1.1243316e-06, ..., 2.7567938e-05,\n",
       "        3.9452794e-03, 3.2017820e-03],\n",
       "       [2.9822587e-04, 3.8295589e-06, 4.7481614e-03, ..., 3.5146550e-05,\n",
       "        8.3979721e-05, 1.0940158e-06]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c80eaf74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-05 12:37:55.071968: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:345] Ignored output_format.\n",
      "2021-08-05 12:37:55.072050: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:348] Ignored drop_control_dependency.\n",
      "2021-08-05 12:37:55.072062: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:354] Ignored change_concat_input_ranges.\n",
      "2021-08-05 12:37:55.072341: I tensorflow/cc/saved_model/reader.cc:38] Reading SavedModel from: models/model\n",
      "2021-08-05 12:37:55.073763: I tensorflow/cc/saved_model/reader.cc:90] Reading meta graph with tags { serve }\n",
      "2021-08-05 12:37:55.073785: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: models/model\n",
      "2021-08-05 12:37:55.079862: I tensorflow/cc/saved_model/loader.cc:206] Restoring SavedModel bundle.\n",
      "2021-08-05 12:37:55.125313: I tensorflow/cc/saved_model/loader.cc:190] Running initialization op on SavedModel bundle at path: models/model\n",
      "2021-08-05 12:37:55.138387: I tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 66048 microseconds.\n",
      "2021-08-05 12:37:55.276585: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:345] Ignored output_format.\n",
      "2021-08-05 12:37:55.276658: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:348] Ignored drop_control_dependency.\n",
      "2021-08-05 12:37:55.276670: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:354] Ignored change_concat_input_ranges.\n",
      "2021-08-05 12:37:55.279538: I tensorflow/cc/saved_model/reader.cc:38] Reading SavedModel from: models/model\n",
      "2021-08-05 12:37:55.282286: I tensorflow/cc/saved_model/reader.cc:90] Reading meta graph with tags { serve }\n",
      "2021-08-05 12:37:55.282324: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: models/model\n",
      "2021-08-05 12:37:55.291968: I tensorflow/cc/saved_model/loader.cc:206] Restoring SavedModel bundle.\n",
      "2021-08-05 12:37:55.347636: I tensorflow/cc/saved_model/loader.cc:190] Running initialization op on SavedModel bundle at path: models/model\n",
      "2021-08-05 12:37:55.356637: I tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 77117 microseconds.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: 9, output_inference_type: 9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_TF)\n",
    "model_no_quant_tflite = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(MODEL_NO_QUANT_TFLITE, \"wb\").write(model_no_quant_tflite)\n",
    "# Convert the model to the TensorFlow Lite format with quantization\n",
    "def representative_dataset():\n",
    "  for i in range(500):\n",
    "    yield([(X_train[i].reshape(-1,28,28,1)).astype(np.float32)])\n",
    "# Set the optimization flag.\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# Enforce integer only quantization\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "# Provide a representative dataset to ensure we quantize correctly.\n",
    "converter.representative_dataset = representative_dataset\n",
    "# print((X_train[1][0]))\n",
    "\n",
    "model_tflite = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(MODEL_TFLITE, \"wb\").write(model_tflite)\n",
    "\n",
    "y_test_pred_tf = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0f756b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tflite(tflite_model, x_test):\n",
    "  # Prepare the test data\n",
    "  x_test_ = x_test.copy()\n",
    "  x_test_ = x_test_.reshape((x_test.size, 1))\n",
    "  x_test_ = x_test_.astype(np.float32)\n",
    "\n",
    "  # Initialize the TFLite interpreter\n",
    "  interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "  interpreter.allocate_tensors()\n",
    "\n",
    "  input_details = interpreter.get_input_details()[0]\n",
    "  output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "  # If required, quantize the input layer (from float to integer)\n",
    "  input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "  if (input_scale, input_zero_point) != (0.0, 0):\n",
    "    x_test_ = x_test_ / input_scale + input_zero_point\n",
    "    x_test_ = x_test_.astype(input_details[\"dtype\"])\n",
    "  \n",
    "  # Invoke the interpreter\n",
    "  y_pred = np.empty(x_test_.size, dtype=output_details[\"dtype\"])\n",
    "  for i in range(len(x_test_)):\n",
    "    interpreter.set_tensor(input_details[\"index\"], [x_test_[i]])\n",
    "    interpreter.invoke()\n",
    "    y_pred[i] = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "  \n",
    "  # If required, dequantized the output layer (from integer to float)\n",
    "  output_scale, output_zero_point = output_details[\"quantization\"]\n",
    "  if (output_scale, output_zero_point) != (0.0, 0):\n",
    "    y_pred = y_pred.astype(np.float32)\n",
    "    y_pred = (y_pred - output_zero_point) * output_scale\n",
    "\n",
    "  return y_pred\n",
    "\n",
    "def evaluate_tflite(tflite_model, x_test, y_true):\n",
    "  global model\n",
    "  y_pred = predict_tflite(tflite_model, x_test)\n",
    "  loss_function = tf.keras.losses.get(model.loss)\n",
    "  loss = loss_function(y_true, y_pred).numpy()\n",
    "  return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a6dc02b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "# y_test_pred_tf = model.predict(X_test)\n",
    "y_test_pred_no_quant_tflite = predict_tflite(model_no_quant_tflite, X_test)\n",
    "# y_test_pred_tflite = predict_tflite(model_tflite, X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
